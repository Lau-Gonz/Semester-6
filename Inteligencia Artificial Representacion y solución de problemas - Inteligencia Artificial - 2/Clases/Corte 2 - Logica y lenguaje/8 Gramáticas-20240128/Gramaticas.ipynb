{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./imagenes/Macc.png\" width=\"400\"/></td>\n",
    "        <td>&nbsp;</td>\n",
    "        <td>\n",
    "            <h1 style=\"color:blue;text-align:left\">Inteligencia Artificial</h1></td>\n",
    "        <td>\n",
    "            <table><tr>\n",
    "            <tp><p style=\"font-size:150%;text-align:center\">Notebook</p></tp>\n",
    "            <tp><p style=\"font-size:150%;text-align:center\">Gramáticas Independientes del Contexto</p></tp>\n",
    "            </tr></table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo <a class=\"anchor\" id=\"inicio\"></a>\n",
    "\n",
    "En este notebook nos familiarizaremos con el uso de la librería `nltk` para procesar Gramáticas Independientes del Contexto. Veremos cómo crear gramáticas, generar cadenas y encontrar los árboles de análisis. También escribiremos nuestra propia \"toy grammar\" para el español.\n",
    "\n",
    "Este notebook está basado en los capítulos 8 y 9 de [1], el cual puede consultarse en la [página web](https://www.nltk.org/book/ch08.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ir a ejercicio 1](#ej1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias\n",
    "\n",
    "Al iniciar el notebook o reiniciar el kerner, se pueden cargar todas las dependencias de este notebook al correr las siguientes celdas. Este también es el lugar para instalar las dependencias que podrían hacer falta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En linux o mac\n",
    "#!pip3 install nltk\n",
    "#!pip3 install svgling\n",
    "#!pip3 install pandas\n",
    "#!pip3 install random\n",
    "\n",
    "# En windows\n",
    "#!py -m pip install nltk\n",
    "#!py -m pip install svgling\n",
    "#!py -m pip install pandas\n",
    "#!py -m pip install random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG, parse\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser\n",
    "from nltk.parse.generate import generate\n",
    "from random import sample\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secciones\n",
    "\n",
    "Desarrollaremos la explicación en las siguientes secciones:\n",
    "\n",
    "* [Una gramática muy simple.](#gram1)\n",
    "* [Parsing.](#parsing)\n",
    "* [Características gramaticales.](#caracs)\n",
    "* [Evaluación de una gramática](#eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una gramática muy simple\n",
    "<a class=\"anchor\" id=\"gram1\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "**Gramática abstracta**\n",
    "\n",
    "Vamos a comenzar con el ejemplo que vimos en las diapositivas de una gramática muy sencilla:\n",
    "\n",
    "$$\n",
    "    \\begin{split}\n",
    "      A &\\to 0A1\\\\\n",
    "      A &\\to B\\\\\n",
    "      B &\\to 2\n",
    "    \\end{split}\n",
    "$$\n",
    "\n",
    "Esta gramática podemos escribirla como una cadena e importarla mediante el método `fromstring()` de la clase `CFG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas1 = \"\"\"\n",
    "A -> '0' A '1' | B\n",
    "B -> '2'\n",
    "\"\"\"\n",
    "gram_abs = CFG.fromstring(reglas1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el objeto creado tiene el símbolo incial, que se puede visualizar mediante `start()`, y también las reglas de producción, mediante `productions()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_abs.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_abs.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que también hemos importado la función `generate`, mediante la cual podemos generar todas las cadenas que se puedan obtener usando la gramática. Como esta es una gramática recursiva (es decir, que al aplicar la regla de reescritura sobre una cadena podemos aplicarla de nuevo una y otra vez), debemos dar un límite a la profundidad de los árboles que queremos generar. En este caso, daremos la profundidad máxima de 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(generate(grammar=gram_abs, depth=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que hemos generado tres cadenas, a saber, `00211`, `021` y `2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gramática sencilla para el español**\n",
    "\n",
    "Veamos ahora cómo crear nuestra primera gramática para el español. Este primer ejemplo será muy sencillo, pues solo uniremos un término con un predicado para formar oraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas2 = \"\"\"\n",
    "O -> SN V\n",
    "SN -> D N\n",
    "V -> 'camina'\n",
    "D -> 'un' | 'una'\n",
    "N -> 'hombre' | 'mujer'\n",
    "\"\"\"\n",
    "gramatica = nltk.CFG.fromstring(reglas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos ahora todas las oraciones que se puedan obtener mediante esta pequeña gramática. Como ell no es recursiva, no es necesario poner un límite de profundidad para los árboles generados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(generate(gramatica))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing <a class=\"anchor\" id=\"parsing\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "El parsing es un proceso mediante el cual se obtiene uno o todos los árboles de análisis de una cadena dada. Más adelante en el curso hablaremos con más calma sobre algunas maneras sencillas para hacer parsing. Por el momento, es importante saber que la librería `nltk` ya tiene implementada varias clases para realizar parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gramática abstracta**\n",
    "\n",
    "Veámos cómo se realiza el parsing mediante el algoritmo de descenso recursivo, usando como ejemplo la gramática abstracta definida más arriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto que implementa \n",
    "# el método de descenso recursivo:\n",
    "rd = RecursiveDescentParser(gram_abs, trace=2)\n",
    "#                              ^\n",
    "#                           gramática\n",
    "#                           abstracta\n",
    "\n",
    "# Creamos nuestra oración a analizar:\n",
    "oracion1 = '0 2 1'.split()\n",
    "\n",
    "# Realizamos el parsing:\n",
    "trees = rd.parse(oracion1)\n",
    "\n",
    "# Visualizamos (de manera lineal):\n",
    "for t in trees:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que el objeto tiene un atributo `trace`, el cual puede inicializarse con el valor 0 para evitar la visualización del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un objeto que implementa \n",
    "# el método de descenso recursivo:\n",
    "rd = RecursiveDescentParser(gram_abs, trace=0)\n",
    "#                                           ^\n",
    "#                                        info a\n",
    "#                                        visualizar\n",
    "\n",
    "# Creamos nuestra oración a analizar:\n",
    "oracion1 = '0 2 1'.split()\n",
    "\n",
    "# Realizamos el parsing:\n",
    "trees = rd.parse(oracion1)\n",
    "\n",
    "# Visualizamos (de manera lineal):\n",
    "for t in trees:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe también que la anterior visualización no es muy explícita para ver el árbol. En efecto, no se ve ningún árbol. Lo que obtenemos es una cadena con la representación lineal de uno. Para poder tener un árbol, podemos echar mano de la clase `Tree`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un árbol usando el método fromstring:\n",
    "tree = Tree.fromstring(str(t))\n",
    "\n",
    "# Visualizamos el árbol:\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej1\"></a>**Ejercicio 1:** \n",
    "\n",
    "([Próximo ejercicio](#ej2))\n",
    "\n",
    "Visualice el árbol de análisis de cada una de las oraciones generadas mediante la \"toy grammar\" del español que definimos más arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características gramaticales\n",
    "<a class=\"anchor\" id=\"caracs\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "Hasta ahora, nuestra toy grammar genera oraciones no gramaticales, como \"una hombre camina\". Vamos a usar características semánticas para bloquear este tipo de combinaciones. Comencemos por implementar la característica del género, que se aplica tanto para sustantivos como para determinantes:\n",
    "\n",
    "- GEN, género (m=masculino, f=femenino)\n",
    "\n",
    "Observe que ahora vamos a usar una clase distinta, que se llama `FeatureGrammar`, mediante la cual implementamos la gramática con características. También tenemos que usar un parser distinto, que se llama `FeatureEarlyChartParser`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la gramática\n",
    "toy_g = \"\"\"\n",
    "% start O\n",
    "O -> SN V\n",
    "SN[GEN=?g] -> D[GEN=?g] N[GEN=?g]\n",
    "D[GEN=m] -> 'un'\n",
    "D[GEN=f] -> 'una'\n",
    "N[GEN=m] -> 'hombre'\n",
    "N[GEN=f] -> 'mujer'\n",
    "V -> 'camina'\n",
    "\"\"\"\n",
    "\n",
    "# Instanciamos el objeto\n",
    "gramatica_f = FeatureGrammar.fromstring(toy_g)\n",
    "\n",
    "# Instanciamos el parser\n",
    "parser = FeatureEarleyChartParser(gramatica_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar el parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = utils.parsear(o1, parser, verbose=True)\n",
    "tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = utils.parsear(o2, parser, verbose=True)\n",
    "tree2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de una gramática\n",
    "\n",
    "<a class=\"anchor\" id=\"eval\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante observar que una gramática nos permite clasificar cadenas como gramaticales (es decir, aquellas para las cuales el parser nos devolverá un árbol de análisis) o no gramaticales. Por ejemplo, la cadena \"un hombre camina\" es clasificada como gramatical por nuestra `toy_g` mientras que \"un mujer camina\" es clasificada como no gramatical. \n",
    "\n",
    "Adicionalmente, observe que la clasificación de una oración depende de una gramática. Por ejemplo, la gramática `reglas2` creada más arriba clasifica ambas cadenas como gramaticales. Veamos este resultado de manera gráfica mediante la siguiente tabla:\n",
    "\n",
    "| | `reglas2` | `toy_g` | Gold |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| un hombre camina | gramatical | gramatical  | gramatical  |\n",
    "| un mujer camina | gramatical | no gramatical | no gramatical |\n",
    "\n",
    "El desempeño de las gramáticas lo evaluamos de acuerdo a un \"gold standard\". En este caso, el \"gold\" es un conjunto de oraciones, que nosotros consideramos independientemente como gramaticales.\n",
    "\n",
    "¿Cómo evaluamos el desempeño de una gramática respecto al \"gold\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matriz de confusión**\n",
    "\n",
    "Se definen las medidas de **precision**, **recall** y **accuracy** de acuerdo a la siguiente matriz de confusión:\n",
    "\n",
    "<img src=\"./imagenes/confusion.png\" width=\"500\"/>\n",
    "\n",
    "En otras palabras, la **precision** nos dice qué porcentaje es correcto de las oraciones que fueron clasificadas como gramaticales:\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}\n",
    "$$\n",
    "\n",
    "El **recall** nos dice qué porcentaje de las oraciones gramaticales fue clasificado como gramatical:\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}\n",
    "$$\n",
    "\n",
    "El **accuracy** nos dice qué porcentaje de oraciones en todo el conjunto fue clasificado correctamente:\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{\\text{true positives} + \\text{true negatives}}{\\text{true positives} + \\text{false positives} + \\text{true negatives} + \\text{false negatives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej2\"></a>**Ejercicio 2:** \n",
    "\n",
    "([Anterior ejercicio](#ej1)) ([Próximo ejercicio](#ej3))\n",
    "\n",
    "¿Cuál es el precision, recall y accuracy de las gramáticas `reglas2` y `toy_g`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medida F1**\n",
    "\n",
    "Una manera de combinar precision y recall en una sola medida se llama la medida F1, definida como:\n",
    "\n",
    "$$\n",
    "F1 = \\frac{2*\\textbf{precision}*\\textbf{recall}}{\\textbf{precision} + \\textbf{recall}}\n",
    "$$\n",
    "\n",
    "La medida F1 toma valores entre 0 y 1. Cuanto más cercano a 1 significa un mejor desempeño.\n",
    "\n",
    "Observe que F1(`reglas2`) = 0.666 y que F1(`toy_g`) = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej3\"></a>**Ejercicio 3:** \n",
    "\n",
    "([Anterior ejercicio](#ej2)) ([Próximo ejercicio](#ej4))\n",
    "    \n",
    "Implemente la función F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1(tp, fp, fn, tn, verbose=False):\n",
    "    '''\n",
    "    Devuelve la medida F1.\n",
    "    Input:\n",
    "        - tp, número de verdaderos positivos\n",
    "        - fp, número de falsos positivos\n",
    "        - fn, número de falsos negativos\n",
    "        - tn, número de verdaderos negativos\n",
    "        - verbose, booleano para presentar información\n",
    "    '''\n",
    "    pass\n",
    "    # AQUÍ SU CÓDIGO\n",
    "    \n",
    "    # HASTA AQUÍ SU CÓDIGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la diferencia entre **accuracy** y F1. Considere el siguiente resultado (ficticio) de la clasificación dada por una gramática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'oracion':['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], \n",
    "                     'gold':['no']*9 + ['si'],\n",
    "                     'resultado':['no']*10})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta gramática tiene accuracy = 0.909, pero un F1 = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluando gramáticas**\n",
    "\n",
    "Podemos usar la función `test_gramatica_carac()` para evaluar una gramática que hayamos escrito. Por ejemplo, podemos evaluar la sencilla gramática sin características `reglas2`, y comparar su desempeño con el de la gramática con características `toy_g`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reglas2)\n",
    "f1 = utils.test_gramatica_carac('oraciones.csv', reglas2, trace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toy_g)\n",
    "f1 = utils.test_gramatica_carac('oraciones.csv', toy_g, trace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el valor F1 de `toy_g` es 0.4, que es un poco mejor que el 0.3 de `reglas2`. No obstante, es posible hacerlo mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej4\"></a>**Ejercicio 4:** \n",
    "\n",
    "([Anterior ejercicio](#ej3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el dataset `combinaciones.csv`, el cual contiene los datos para el problema de clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('combinaciones.csv')\n",
    "mask = sample(range(data.shape[0]), 5)\n",
    "data.iloc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su tarea es escribir una gramática independiente del contexto con características gramaticales para obtener un valor F1 mayor a 0.95. Las características gramaticales que debe usar son las siguientes:\n",
    "\n",
    "    - GEN, género (m=masculino, f=femenino)\n",
    "        Para sustantivos, determinantes y sintagmas nominales.  \n",
    "    - NUM, si es plural o no (sg=singular, pl=plural)\n",
    "        Para sustantivos, determinantes, sintagmas nominales y verbos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramatica = \"\"\"\n",
    "# AQUÍ SU CÓDIGO\n",
    "\n",
    "# HASTA AQUÍ SU CÓDIGO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.test_gramatica_carac('oraciones.csv', gramatica, trace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En este notebook usted aprendió a\n",
    "\n",
    "* Implementar gramáticas independientes del contexto usando las herramientas de `nltk`.\n",
    "* Implementar características gramanticales.\n",
    "* Usar un parser para obtener el árbol de análisis de una oración.\n",
    "* Escribir gramáticas para clasificar oraciones como gramaticales o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía \n",
    "\n",
    "[1] Bird, S. and Klein, E. and Loper, E., 2009. Natural Language Processing with Python: Analyzing text with the Natural Language Toolkit. O’Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
