{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpmFfXsQ0dYI"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./imagenes/Macc.png\" width=\"400\"/></td>\n",
    "        <td>&nbsp;</td>\n",
    "        <td>\n",
    "            <h1 style=\"color:blue;text-align:left\">Inteligencia Artificial</h1></td>\n",
    "        <td>\n",
    "            <table><tr>\n",
    "            <tp><p style=\"font-size:150%;text-align:center\">El mundo del Wumpus</p></tp>\n",
    "            </tr></table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3SkDSWJ0dYJ"
   },
   "source": [
    "# Objetivo <a class=\"anchor\" id=\"inicio\"></a>\n",
    "\n",
    "Vamos a entrar de lleno en el enfoque basado en agentes de la Inteligencia Artificial. Para comprenderlo mejor, debemos tomar la perspectiva de un agente que tiene que superar un reto en un minimundo. En este notebook, el minimundo es el mundo del Wumpus y uno de los objetivos es familiarizarnos con dicho entorno. Adicionalmente, implementaremos un programa de agente híbrido, el cuál incluirá un modelo lógico del mundo y una solución de objetivos basada en planeación de rutas.\n",
    "\n",
    "Adaptado de Russell & Norvig (2016), cap. 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ir al ejercicio 1](#ej1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias\n",
    "\n",
    "Al iniciar el notebook o reiniciar el kerner se pueden cargar todas las dependencias de este notebook corriendo las siguientes celdas. Este también es el lugar para instalar las dependencias que podrían hacer falta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Del notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logica import *\n",
    "from ambientes import *\n",
    "from agentes import *\n",
    "from utils import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HnQ_gA70dYL"
   },
   "source": [
    "# Secciones\n",
    "\n",
    "En este notebook desarrollaremos los siguientes aspectos del problema:\n",
    "\n",
    "* [El mundo del Wumpus.](#wumpus)\n",
    "* [Agente híbrido.](#hibrido)\n",
    "* [Representando el mundo mediante lógica proposicional.](#representacion)\n",
    "* [Inferencias y queries](#queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4x5lJfd0dYM"
   },
   "source": [
    "# El mundo del Wumpus <a class=\"anchor\" id=\"wumpus\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "El siguiente problema se conoce como *El mundo del Wumpus* (Yob, 1975). Imagine una caverna muy oscura, representada por una rejilla de $4\\times 4$ rodeada de muros. Un agente (nuestro héroe de la historia) puede entrar y salir de la caberna por la casilla (0,0) y puede percibir solamente lo que hay en cada casilla en la que se encuentre. En la caverna hay pozos muy profundos; si cae en uno de ellos, morirá. Lo peor de todo es que hay un mounstro, conocido como el Wumpus, el cual se comerá vivo al agente si éste entra a su casilla. ¿Por qué el agente entraría a un lugar como este? ¡Porque en alguna casilla de la cueva hay un montón de oro!\n",
    "\n",
    "<img src=\"./imagenes/ejemplo.png\" width=\"400\">\n",
    "\n",
    "Las siguientes son las reglas que gobiernan el mundo:\n",
    "\n",
    "* En cualquier casilla adyacente (no diagonalmente) a un pozo se percibe una brisa; \n",
    "* En cualquier casilla adyacente (no diagonalmente) al Wumpus se percibe un hedor; \n",
    "* En la casilla donde se encuentra el oro se percibe un brillo. \n",
    "* El wumpus nunca se mueve de su casilla.\n",
    "\n",
    "Finalmente, el agente tiene un arco y solo una flecha, con la cual puede matar al Wumpus. Cuando el agente dispara la flecha, ésta seguirá en la misma dirección del agente hasta golpear un muro o clavarse en el Wumpus, quien morirá arrojando un desgarrador grito \"Aaaaaaarrrrgghhhhh\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P60dU8Mg0dYO"
   },
   "source": [
    "<a class=\"anchor\" id=\"ej1\"></a>**Ejercicio 1:** \n",
    "\n",
    "([Próximo ejercicio](#ej2))\n",
    "\n",
    "De acuerdo con la formulación de entornos hecha al comienzo del curso, ¿cuáles características considera usted que tiene este problema?\n",
    "\n",
    "**Ayuda:** Puede usar el comando `$\\checkmark$` para poner un chulito en la opción que desee marcar. \n",
    "\n",
    "| Opción 1 | Opción 2 |\n",
    "| :---: | :---: |\n",
    "| Completamente observable | Parcialmente observable|\n",
    "| Agente único | Multiagente |\n",
    "| Determinista | Estocástico |\n",
    "| Episódico    | secuencial  |\n",
    "| Estático     | dinámico    |\n",
    "| Discreto     | continuo    |\n",
    "| Conocido     | desconocido |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL49lY0r0dYP"
   },
   "source": [
    "La **definición formal del entorno** se hace con base en la definición de las siguientes características:\n",
    "\n",
    "* **Entorno**: Una cueva representada por una rejilla $4\\times 4$ bordeada por muros. El agente siempre comienza en (0, 0) mirando a la derecha. La ubicación del Wumpus se escoge arbitrariamente de manera uniforme en casillas distintas a la inicial. Cualquier casilla distinta de la inicial puede ser un pozo con probabilidad 0.2. El oro puede estar en cualquier casilla, con probabilidad uniforme.\n",
    "\n",
    "* **Actuadores**: El héroe puede moverse `adelante` por una casilla (no es posible moverse adelante cuando hay un muro), `voltearIzquierda` por 90º, o `voltearDerecha` por 90º. Es posible `agarrar` el oro cuando este está en la casilla ocupada por el héroe. También puede `disparar` la flecha en la dirección en que está mirando, la cual seguirá en linea recta hasta golpear un muro. Finalmente, el agente puede `salir` de la cueva, pero solo desde la casilla inicial.\n",
    "\n",
    "* **Sensores**: El héroe percibe un `hedor` cuando llega a la casilla donde está el Wumpus o cuando llega a una de las casillas adyacentes (no diagonalmente). En las casillas adyacentes a un pozo, percibe una `brisa`. En el cuadro donde está el oro, percibe un `brillo`. Cuando se topa con un muro, percibe un `batacazo`. Finalmente, si el Wumpus muere, el heroe percibe un `grito` desde cualquier casilla.\n",
    "\n",
    "* **Medida de desempeño**: +1000 por salir de la cueva con el oro; -1000 por caer en un pozo o ser comido por el Wumpus; -1 por cada acción y -10 por usar la flecha. El juego termina cuando el heroe muere o sale de la cueva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESao4G9n0dYP"
   },
   "source": [
    "\n",
    "**Implementación del entorno**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos el mundo y percibimos lo que hay en la primera casilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "W = Wumpus(wumpus=(3,3), oro=(2,2), pozos=[(1,0), (3,1)])\n",
    "state = W.reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el mundo completo mediante el método `pintar_todo()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.pintar_todo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dar una serie de pasos en la oscuridad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "W = Wumpus(wumpus=(3,3), oro=(2,2), pozos=[(1,0), (3,1)])\n",
    "# Create agent\n",
    "agente = Heroe()\n",
    "# Create episode\n",
    "episodio = Episode(environment=W,\\\n",
    "        agent=agente,\\\n",
    "        model_name='Baseline',\\\n",
    "        num_rounds=10)\n",
    "# Include plan\n",
    "camino = [(0,0), (0,1), (1,1), (2,1), (3,1)]\n",
    "acciones = agente.acciones_camino(camino)\n",
    "agente.plan += acciones\n",
    "# Visualize\n",
    "episodio.renderize()\n",
    "# Presentar resumen\n",
    "clear_output()\n",
    "W.pintar_todo()\n",
    "print(W.mensaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente híbrido <a class=\"anchor\" id=\"hibrido\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "\n",
    "Nuestro heroe puede trazar rutas desde la posición en la que se en cuentra hasta una casilla objetivo (similar a lo que hace el agente basado en objetivos para salir del laberinto, el cual desarrollamos en un notebook previo). Idealmente, la casilla objetivo es segura y aún por visitar. Si no hay casillas seguras por visitar, el objetivo es la salida. \n",
    "\n",
    "Aún no hemos mostrado cómo el agente puede determinar si una casilla es segura, sobre lo cual volveremos en un momento.\n",
    "\n",
    "Por ahora, las reglas que sigue el agente son las siguientes:\n",
    "\n",
    "* Si percibe el brillo (indicando que en esa casilla está el oro), lo agarra, traza una ruta a la salida y sale de la caberna con una sonrisa en la boca y un montón de oro en el bolsillo.\n",
    "* Si no percibe brillo, considera las casillas seguras que no haya visitado y se dirige a una de ellas.\n",
    "* Si todas las casillas seguras ya han sido visitadas, traza una ruta a la salida y sale con las manos vacías y la cola entra las piernas.\n",
    "\n",
    "<img src=\"./imagenes/program.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej2\"></a>**Ejercicio 2:** \n",
    "\n",
    "([Anterior ejercicio](#ej1)) ([Próximo ejercicio](#ej3))\n",
    "\n",
    "Modifique el camino en la línea 11 de la celda de código anterior para que el agente llegue hasta el oro, lo agarre, luego regrese a la salida y salga. En dicha línea de código, utilice la mínima cantidad de acciones. Es decir, aproveche las reglas que ya sigue el agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej3\"></a>**Ejercicio 3:** \n",
    "\n",
    "([Anterior ejercicio](#ej2)) ([Próximo ejercicio](#ej4))\n",
    "\n",
    "Modifique el camino en la línea 11 de la celda de código anterior para que el agente:\n",
    "\n",
    "1. Camine hasta la esquina superior izquierda\n",
    "2. Mire al este\n",
    "3. Dispare la flecha,\n",
    "4. Camine hasta el oro, lo agarre, regrese a la salida y salga. \n",
    "\n",
    "**Nota:** Tal vez deba modificar el número de rondas máximo al crear la clase `Episode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representación del mundo del Wumpus en lógica proposicional <a class=\"anchor\" id=\"representacion\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "Vamos a construir un modelo del Mundo del Wumpus mediante lógica proposicional. Para lograr esto, vamos a hacer que el agente sea capaz de:\n",
    "\n",
    "* Representar las reglas del mundo del Wumpus.\n",
    "* Combinar información sensorial con las reglas del mundo.\n",
    "* Razonar sobre cuáles casillas adyacentes es seguro visitar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Letras proposicionales:**\n",
    "\n",
    "Para comenzar la representación del Mundo del Wumpus, usaremos las siguientes letras proposicionales:\n",
    "\n",
    "* `hedor(a, b)` es verdadero sii el agente huele un hedor en la casilla $(a,b)$.\n",
    "* `brisa(a, b)` es verdadero sii el agente siente una brisa en la casilla $(a,b)$.\n",
    "* `brillo(a, b)` es verdadero sii el agente ve un brillo en la casilla $(a,b)$.\n",
    "* `batacazo(a, b)` es verdadero sii el agente siente un batacazo en la casilla $(a,b)$.\n",
    "* `grito(a, b)` es verdadero sii el agente escucha un grito en la casilla $(a,b)$.\n",
    "* `pozo(a, b)` es verdadero sii en la casilla $(a,b)$ hay un pozo.\n",
    "* `wumpus(a, b)` es verdadero sii en la casilla $(a,b)$ está el Wumpus.\n",
    "* `segura(a, b)` es verdadero sii la casilla $(a,b)$ es segura para transitar.\n",
    "\n",
    "**Nota sobre las letras proposicionales:** Técnicamente hablando, las anteriores son fórmulas de la lógica de predicados. No obstante, ellas son un tipo particular de fórmulas, a saber, *fórmulas fundamentadas*. Es decir, ellas no tienen variables. Las fórmulas fundamentadas son equivalentes a letras proposicionales y podemos usar los recursos disponibles para este tipo de lógica. Usaremos mucho este truco en el resto del curso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De percepciones a fórmulas**\n",
    "\n",
    "Ahora usamos fórmulas de la lógica proposicional para representar aspectos del mundo. Observe que debemos partir de las percepciones del agente, las cuales vienen dadas mediante una lista:\n",
    "\n",
    "['hedor'/None, 'brisa'/None, 'brillo'/None, 'batacazo'/None, 'grito'/None]\n",
    "\n",
    "Usando el método `interp_percepto()` de la clase `Heroe` obtenemos una fórmula con la conjunción de letras proposionales que representan los perceptos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "W = Wumpus(wumpus=(3,3), oro=(2,2), pozos=[(1,0), (3,1)])\n",
    "state = W.reset()\n",
    "W.render()\n",
    "agente = Heroe()\n",
    "agente.states.append(state)\n",
    "print(agente.interp_percepto())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representando el mundo mediante reglas**\n",
    "\n",
    "Ahora consideramos la información sobre la relación entre los pozos y la brisa. Observe que las reglas del mundo dicen que en las casillas adyacentes a un pozo se siente una brisa. De manera equivalente, se sigue que si el agente no siente una briza en una casilla, entonces no hay un pozo en las casillas adyacentes. Resulta natural representar esto como una implicación:\n",
    "\n",
    "Si el agente está en $(0,0)$ y no siente una brisa, entonces no hay pozo en $(1,0)$ ni en $(0,1)$.\n",
    "\n",
    "No obstante, vamos a ceñirnos a las limitaciones de la base de conocimiento. Esto es, vamos a usar solo el lenguaje de las reglas. Así pues, en lugar de una única fórmula, debemos incluir en la base de conocimiento las dos siguientes reglas:\n",
    "\n",
    "* Si no percibo una brisa en $(0,0)$, no hay pozo en $(1,0)$ \n",
    "* Si no percibo una brisa en $(0,0)$, no hay pozo en $(0,1)$ \n",
    "\n",
    "Y esto para cada casilla:\n",
    "\n",
    "* Si no percibo una brisa en $(1,0)$, no hay un pozo en $(0,0)$ \n",
    "* Si no percibo una brisa en $(1,0)$, no hay un pozo en $(2,0)$ \n",
    "* Si no percibo una brisa en $(1,0)$, no hay un pozo en $(1,1)$ \n",
    "* $\\vdots$\n",
    "\n",
    "La forma general de todas estas reglas es que si el agente está en la casilla $(x,y)$ y no siente una brisa, entonces no hay pozo en ninguna de sus casillas adyacentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brisa_pozo(self):\n",
    "    formulas = []\n",
    "    casillas = self.adyacentes(self.loc)\n",
    "    for c in casillas:\n",
    "        formulas += [\n",
    "            f'-brisa{self.loc}>-pozo{c}',                \n",
    "        ]\n",
    "    return formulas\n",
    "\n",
    "setattr(Heroe, 'brisa_pozo', brisa_pozo)\n",
    "\n",
    "agente = Heroe()\n",
    "agente.brisa_pozo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej4\"></a>**Ejercicio 4:** \n",
    "\n",
    "([Anterior ejercicio](#ej3)) ([Próximo ejercicio](#ej5))\n",
    "\n",
    "Escriba un código que genere una lista de fórmulas `hedor_wumpus` que contenga todas las implicaciones sobre la relación entre el Wumpus y el hedor dependiendo de la casilla en que se encuentra el agente.\n",
    "\n",
    "Si el agente está en la casilla $(0,0)$, la respuesta debe ser:\n",
    "\n",
    "```\n",
    "['-hedor(0, 0)>-wumpus(1, 0)', '-hedor(0, 0)>-wumpus(0, 1)']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hedor_wumpus(self):\n",
    "    formulas = []\n",
    "    # AQUÍ COMENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    return formulas\n",
    "\n",
    "setattr(Heroe, 'hedor_wumpus', hedor_wumpus)\n",
    "\n",
    "agente = Heroe()\n",
    "agente.hedor_wumpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej5\"></a>**Ejercicio 5:** \n",
    "\n",
    "([Anterior ejercicio](#ej4)) ([Próximo ejercicio](#ej6))\n",
    "\n",
    "Escriba un código que genere una lista de fórmulas `casilla_segura`, la cual debe contener todas reglas que dicen que si en una casilla no hay ni pozo ni Wumpus, entonces es segura. (Vamos a ignorar por el momento el hecho de que la casilla sería segura incluso habiendo hedor, porque el Wumpus podría no estar vivo.)\n",
    "\n",
    "* Si no hay ni pozo ni Wumpus en $(0,0)$, entonces $(0,0)$ es segura.\n",
    "* $\\vdots$\n",
    "\n",
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "['-pozo(0, 0)&-wumpus(0, 0)>segura(0, 0)',\n",
    " '-pozo(0, 1)&-wumpus(0, 1)>segura(0, 1)',\n",
    " '-pozo(0, 2)&-wumpus(0, 2)>segura(0, 2)',\n",
    " '-pozo(0, 3)&-wumpus(0, 3)>segura(0, 3)',\n",
    " '-pozo(1, 0)&-wumpus(1, 0)>segura(1, 0)',\n",
    " '-pozo(1, 1)&-wumpus(1, 1)>segura(1, 1)',\n",
    " '-pozo(1, 2)&-wumpus(1, 2)>segura(1, 2)',\n",
    " '-pozo(1, 3)&-wumpus(1, 3)>segura(1, 3)',\n",
    " '-pozo(2, 0)&-wumpus(2, 0)>segura(2, 0)',\n",
    " '-pozo(2, 1)&-wumpus(2, 1)>segura(2, 1)',\n",
    " '-pozo(2, 2)&-wumpus(2, 2)>segura(2, 2)',\n",
    " '-pozo(2, 3)&-wumpus(2, 3)>segura(2, 3)',\n",
    " '-pozo(3, 0)&-wumpus(3, 0)>segura(3, 0)',\n",
    " '-pozo(3, 1)&-wumpus(3, 1)>segura(3, 1)',\n",
    " '-pozo(3, 2)&-wumpus(3, 2)>segura(3, 2)',\n",
    " '-pozo(3, 3)&-wumpus(3, 3)>segura(3, 3)']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casilla_segura(self):\n",
    "    formulas = []\n",
    "    # AQUÍ COMENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    return formulas\n",
    "\n",
    "setattr(Heroe, 'casilla_segura', casilla_segura)\n",
    "\n",
    "agente = Heroe()\n",
    "agente.casilla_segura()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencias y queries <a class=\"anchor\" id=\"queries\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "Ya tenemos todo lo que necesitamos para crear una base de conocimiento inicial. Con esta base podemos implementar un programa de agente que permita transitar por todas las casillas seguras. \n",
    "\n",
    "Comenzamos por inicializar la base de conocimiento así:\n",
    "\n",
    "* Los datos serán la percepción sensorial, la posición y dirección actual del agente.\n",
    "* Las reglas son la dinámica del mundo que hemos codificado hasta ahora. Estas reglas incluyen:\n",
    "    - `brisa_pozo`\n",
    "    - `hedor_wumpus`\n",
    "    - `casilla_segura`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(0,2), oro=(3,2), pozos=[(2,0)])\n",
    "W.render()\n",
    "agente = Heroe()\n",
    "state = W.reset()\n",
    "agente.states.append(state)\n",
    "c = agente.interp_percepto()\n",
    "for hecho in c.split('&'):\n",
    "    agente.base.tell(hecho)\n",
    "print(\"¡Base de conocimiento creada!\")\n",
    "print(agente.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, observe que podemos utilizar el método `ask` de la clase `LPQuery` para hacer la consulta a la base de conocimiento acerca de si una casilla es segura o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetivo = 'segura(1, 0)'\n",
    "print(\"Objetivo:\", objetivo)\n",
    "print()\n",
    "print(\"Datos:\", agente.base.hechos)\n",
    "print()\n",
    "print(\"Reglas aplicables para el objetivo:\")\n",
    "reglas_objeto = agente.base.reglas_aplicables(objetivo)\n",
    "for r in reglas_objeto:\n",
    "    print(' & '.join(r.antecedente), \">\", r.consecuente)\n",
    "res = agente.base.ask(objetivo)\n",
    "print()\n",
    "print(\"Resultado de la consulta:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ej6\"></a>**Ejercicio 6:** \n",
    "\n",
    "([Anterior ejercicio](#ej5))\n",
    "\n",
    "Cree un código que implemente el método `agente.adyacentes_seguras()` que devuelva una lista con las casillas adyacentes seguras de acuerdo a la base de conocimiento del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adyacentes_seguras(self):\n",
    "    casillas_seguras = []\n",
    "    # AQUÍ COMIENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    return casillas_seguras\n",
    "\n",
    "setattr(Heroe,\"adyacentes_seguras\",adyacentes_seguras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe su código con la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(3,3), pozos=[(2,0), (2,2)])\n",
    "state = W.reset()\n",
    "agente = Heroe()\n",
    "agente.states.append(state)\n",
    "c = agente.interp_percepto()\n",
    "for hecho in c.split('&'):\n",
    "    agente.base.tell(hecho)\n",
    "adyacentes_seguras = agente.adyacentes_seguras()\n",
    "assert(adyacentes_seguras == [(1, 0), (0, 1)]), '¡Primer test Fallido!'\n",
    "W = Wumpus(wumpus=(1,0), oro=(3,2), pozos=[(2,0), (2,2)])\n",
    "state = W.reset()\n",
    "agente = Heroe()\n",
    "agente.states.append(state)\n",
    "c = agente.interp_percepto()\n",
    "for hecho in c.split('&'):\n",
    "    agente.base.tell(hecho)\n",
    "adyacentes_seguras = agente.adyacentes_seguras()\n",
    "assert(adyacentes_seguras == []), '¡Segundo test Fallido!'\n",
    "# Create environment\n",
    "W = Wumpus(wumpus=(3,3), oro=(2,2), pozos=[(2,0), (3,1)])\n",
    "# Create agent\n",
    "agente = Heroe()\n",
    "# Create episode\n",
    "episodio = Episode(environment=W,\\\n",
    "        agent=agente,\\\n",
    "        model_name='Baseline',\\\n",
    "        num_rounds=15)\n",
    "# Include plan\n",
    "camino_ida = [(0,0), (0,1), (1,1)]\n",
    "acciones = agente.acciones_camino(camino_ida)\n",
    "agente.plan += acciones\n",
    "episodio.run()\n",
    "adyacentes_seguras = agente.adyacentes_seguras()\n",
    "assert(adyacentes_seguras == [(1, 3), (0, 2)]), '¡Tercer test Fallido!'\n",
    "# Create environment\n",
    "W = Wumpus(wumpus=(1,2), oro=(2,2), pozos=[(2,0), (3,1)])\n",
    "# Create agent\n",
    "agente = Heroe()\n",
    "# Create episode\n",
    "episodio = Episode(environment=W,\\\n",
    "        agent=agente,\\\n",
    "        model_name='Baseline',\\\n",
    "        num_rounds=15)\n",
    "# Include plan\n",
    "camino_ida = [(0,0), (0,1), (0,2)]\n",
    "acciones = agente.acciones_camino(camino_ida)\n",
    "agente.plan += acciones\n",
    "episodio.run()\n",
    "adyacentes_seguras = agente.adyacentes_seguras()\n",
    "assert(adyacentes_seguras == [(1, 0), (0, 1)]), '¡Cuarto test Fallido!'\n",
    "print('¡Tests superados!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evaluamos al agente sobre el test suite para encontrar el promedio de la suma de las recompensas y el porcentaje de éxito en que el agente logra salir con el oro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment\n",
    "exp = Experiment(num_rounds=100, \\\n",
    "                 num_episodes=1)\n",
    "# Create and load environment\n",
    "exp.load_test_suite(\"test_suite_wumpus.json\")\n",
    "# Create agent\n",
    "agente = Heroe()\n",
    "# Run the experiment\n",
    "exp.run_experiment(agents=[agente], \\\n",
    "                   names=['Baseline'], \\\n",
    "                   measures=['histogram'],\\\n",
    "                   verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estos datos observamos lo siguiente. Todos los entornos terminan en menos de 100 rondas. Al revisar el histograma vemos que no hay episodios en los cuales la recompensa esté cercana a -1000, lo cual significa que el agente nunca muere. Podemos asegurar que se logró el objetivo de que el agente explore la cueva del Wumpus de manera segura. \n",
    "\n",
    "En cuanto a la recompensa promedio, es solo de 324 puntos. Al examinar el histograma, vemos que puntajes cerca de 1000 ocurren un poco menos del 30% de las veces, que es cuando el agente logra salir con el oro. El porcentaje exacto de extracción del oro se puede calcular así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = exp.data.groupby(['environment', 'episode']).reward.sum().reset_index()\n",
    "df1['extraction'] = df1['reward'] > 0\n",
    "df1['extraction'].value_counts()\n",
    "print('Porcentaje de extracción:', df1['extraction'].value_counts()[1] / sum(df1['extraction'].value_counts())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El porcentaje de extracción es aproximadamente el 36%. Sería de esperar que mejoras adicionales logren hacer que el agente aumente este porcentaje de recuperación del oro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este notebook usted aprendió\n",
    "\n",
    "* El mundo del Wumpus.\n",
    "* Uso de la lógica proposicional para representar las reglas del mundo del Wumpus."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "arboles_busqueda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
