{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_EkSDpb8LKJ"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"https://s3.amazonaws.com/media-p.slid.es/uploads/1485763/images/9060062/Header.png\" width=\"300\"/></td>\n",
    "        <td>&nbsp;</td>\n",
    "        <td>\n",
    "            <h1 style=\"font-size:200%;color:blue;text-align:center\">    <FONT COLOR=\"blue\">  Frecuencias-Nubes de Palabras  </FONT>         </h1></td>         \n",
    "        <td>\n",
    "            <tp><p style=\"font-size:99%;text-align:center\">PLN </p></tp>\n",
    "            <tp><p style=\"font-size:115%;text-align:center\">Pregrado MACC 2023-2</p></tp>\n",
    "            <tp><p style=\"font-size:115%;text-align:center\">Prof. Fabi√°n S√°nchez</p></tp>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK4q5-en-A5D"
   },
   "source": [
    "**Objetivo de la sesi√≥n:**\n",
    "\n",
    "En esta secci√≥n introducimos algunos elementos del preprocesamiento de textos:\n",
    "- Frecuencias de palabras\n",
    "- Nubes de palabras\n",
    "- Expresiones regulares\n",
    "- Tokenizaci√≥n\n",
    "\n",
    "Estos √∫ltimos conceptos son fundamentales en el proceso de la normalizaci√≥n y limpieza de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.2-cp39-cp39-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wordcloud_cli.exe is installed in 'C:\\Users\\prestamour\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud, ImageColorGenerator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlopen\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from nltk import word_tokenize\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvHqWBrUndt3"
   },
   "source": [
    "<FONT SIZE=5 COLOR=\"purple\"> 1. GU√çA INTRODUCTORIA </FONT>\n",
    "\n",
    "Para motivar la discusi√≥n y abordaje de los conceptos de esta sesi√≥n. Vamos a seguir la siguiente gu√≠a.\n",
    "\n",
    "- Complete el c√≥digo que aparece debajo de cada pregunta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZxnrz51oHTB"
   },
   "source": [
    "1.1 Seleccione un par de p√°rrafos de alguna fuente e internet de un tema que le interese y coloquelo en la variable *texto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-RBOyn4oRxR"
   },
   "outputs": [],
   "source": [
    "texto= \"https://humanidades.com/perro/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUmhM89XoTmR"
   },
   "source": [
    "1.2 ¬øCu√°ntos car√°cteres tiene la variable texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3y-0iruWo3-p"
   },
   "outputs": [],
   "source": [
    "longitud ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pce95ABLpMBR"
   },
   "source": [
    "1.3 ¬øCu√°l es la funci√≥n que convierte toda la cadena de texto a min√∫sculas? ¬øPor qu√© considera que se debe hacer esto en el procesamiento de texto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqVs6iAypapo"
   },
   "outputs": [],
   "source": [
    "texto_minuscula ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfNZ-8Oso6-R"
   },
   "source": [
    "1.4 ¬ø Que funci√≥n permite separar la cadena de texto en expresiones m√°s peque√±as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08V7fOXwpDPQ"
   },
   "outputs": [],
   "source": [
    "lista_texto ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "st_BS_Ksp2l1"
   },
   "source": [
    "1.5 ¬øCu√°l es la longitud de *lista_texto*? Interprete ese valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTwKvhPBp143"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBmPV9geqho6"
   },
   "source": [
    "1.6 Haga una tabla de frecuencias con lista_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clPp_6ELqoKa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAoMxqdkqor6"
   },
   "source": [
    "1.7 Realice una gr√°fica que represente la tabla de frecuencias tomando el top 10 de las palabras que m√°s se repiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFrRCJJkqyu0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g34EZ5NzqzXz"
   },
   "source": [
    "1.8 ¬øQu√© puede observar de esta tabla de frecuencias? ¬øQu√© tipo de palabras fueron las que m√°s se repitieron?\n",
    "\n",
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8XPkOHUrLw8"
   },
   "source": [
    "1.9 Trate de eliminar alguna de estas palabras. Por ejemplo, colocando una restricci√≥n sobre el n√∫mero de car√°cteres de las palabras y de nuevo haga la tabla de frecuencias y el gr√°fico de barras del top 10 de las palabras que m√°s se repiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4uKCONWsDfT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iQxpO4XsCaV"
   },
   "source": [
    "1.10 Concluya sobre los puntos anteriores\n",
    "\n",
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuMX_vR3uaRA"
   },
   "source": [
    "1.11 Ahora, realizaremos dos nubes de palabras\n",
    "\n",
    "- Primero una peque√±a nube de palabras a partir de la lista obtenida en el punto 1.9\n",
    "\n",
    "- Segundo con la lista completa de palabras.\n",
    "\n",
    "**¬°Siga las instrucciones!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDmQrps2uyIe"
   },
   "source": [
    "a. Instale la librer√≠a ***wordcloud***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ya4DWJqu_Jb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziakeAQyu_o0"
   },
   "source": [
    "b. Importe  *WordCloud*  e *ImageColorGenerator* que son las funciones para generar la nube de palabras y darle color a la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTO5S_j9vP3o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAiPKcm7vXPu"
   },
   "source": [
    "c. Utilice el siguiente c√≥digo para generar la nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcN7hEN3vbin"
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=50,                            # tama√±o de la fuente\n",
    "                      max_words=100,                               # m√°ximo de palabras en la nube\n",
    "                      background_color=\"white\").generate(texto)    # color de fondo y el m√©todo de generaci√≥n\n",
    "\n",
    "plt.figure(figsize=(10,10))                                        # tama√±o del gr√°fico\n",
    "plt.imshow(wordcloud)                                              # generaci√≥n del gr√°fico\n",
    "plt.axis(\"off\")                                                    # para que no aparezcan los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igvf_-kJwJki"
   },
   "source": [
    "d. Realice otra nube cambiando algunos par√°metros del c√≥digo anterior. Por ejemplo, tama√±o, n√∫mero de palabras, etc. interpolation=\"bilinear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNYsX5XKsb_q"
   },
   "source": [
    "2. Regresemos a la variable *texto* inicial. Observe que en el texto pueden aparecer car√°cteres que no son letras tales como:\n",
    "\n",
    "- (.) Punto\n",
    "- (,) Coma\n",
    "- (@) Arroba\n",
    "- (#) numeral\n",
    "- (¬ø,?,!) Signos de admiraci√≥n y de pregunta\n",
    "- Entre otros.\n",
    "\n",
    "¬øEn qu√© afectan estos signos al ejercicio anterior?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ekJZuctexS"
   },
   "source": [
    "¬øC√≥mo podr√≠a eliminar car√°cteres especiales en el *texto*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfGiG8-_uP8n"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nj64uXdhsa1q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf5cO7OM2GLL"
   },
   "source": [
    "<FONT SIZE=5 COLOR=\"purple\"> 2. LIBRER√çAS PARA PROCESAMIENTO DE LENGUAJE NATURAL PLN </FONT>\n",
    "\n",
    "Actualmente, existen diferentes librer√≠a que se usan para hacer procesamiento de texto y aplicar metodolog√≠as de procesamiento de lenguaje natural en general (PLN)\n",
    "\n",
    "- **NLTK** (https://www.nltk.org/): Es una librer√≠a desarrollada por Steven Bird y Edward Loper para el Procesamiento de Lenguaje Natural, principalmente en ingl√©s, que tiene herramientas para trabajar con: corpus, recursos l√©xicos, algoritmos de procesamiento de PLN, etc.\n",
    "\n",
    "- **SpaCy** (https://spacy.io/): Es una librer√≠a para el NLP incorpora funcionalidades como Tokenizaci√≥n, Lematizaci√≥n, PoS, NER, etc. en varios idiomas. A diferencia de NLTK que tienen fines de caracter did√°ctico, SpaCy es m√°s aplicado en la soluci√≥n de problemas reales.\n",
    "\n",
    "- **Gensim** (https://radimrehurek.com/gensim/) Es una librer√≠a muy √∫til para vectorizaci√≥n de textos, topic modeling, LDA, etc. Preprocesamiento, entre otras aplicaciones y procesos.\n",
    "\n",
    " A continuaci√≥n, un resumen y comparativas entre diferentes librer√≠as\n",
    "\n",
    " <br>\n",
    "\n",
    "<center><img src=\"https://st11.ning.com/topology/rest/1.0/file/get/2808360875?profile=RESIZE_1024x1024\" alt=\"centered image\" width=\"550\" height=\"700\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: https://noeliagorod.com/2021/11/25/top-librerias-de-python-para-nlp-2/  </FONT> <figcaption></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc53rb6Ynbk4"
   },
   "source": [
    "<FONT SIZE=5 COLOR=\"purple\"> 3. EXPRESIONES REGULARES </FONT>\n",
    "\n",
    "- Es un modelo para b√∫squeda de coincidencias de texto.\n",
    "\n",
    "- Es fundamental en la limpieza de texto para la eliminaci√≥n de car√°cteres o b√∫squedas en texto.\n",
    "\n",
    "- Podemos hacer b√∫squeda especificando el conjuntos de car√°cteres usando los corchetes [].\n",
    "\n",
    "- Si usamos el s√≠mbolo \"^\" despues de \"[\" estaremos buscando los car√°cteres que no pertencen a la lista.\n",
    "\n",
    "Veamos algunos ejemplos. Para profundizar en este tema y ver m√°s posibilidades ver:\n",
    "\n",
    "[*EXPRESIONES REGULARES* ‚ñ∂ üîé](https://developer.mozilla.org/es/docs/Web/JavaScript/Guide/Regular_expressions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCOQcK4OC0he"
   },
   "source": [
    "Iniciamos importante la librer√≠a *¬®re*. Hay dos funciones claves:\n",
    "\n",
    "1. ***findall***. Sirve para encontrar coincidencias de car√°cteres.\n",
    "\n",
    "2- ***sub***. Sustituir car√°cteres por otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxTlJAxgCzzO"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6jATUkcFQ2E"
   },
   "outputs": [],
   "source": [
    "cadena = \"El correo de Fabi√°n S√°nchez con c√≥digo AP89504, es fabian.sanchez@urosario.edu.co y en twitter #PLN!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1691145002318,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "pTIWnM4mF4Wn",
    "outputId": "6f3aa74a-d7f4-43a0-85db-fb4e09edd293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"Fa\"\n",
    "re.findall(patron, cadena)\n",
    "# Observe que se muestran todas las coincidencias de la cadena completa ya que esta dentro de las comilla \"cadena\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8YZ6WlZNZ4g"
   },
   "source": [
    "**.** : punto --- cualquier car√°cter\n",
    "\n",
    "**\\s** : espacio en blanco\n",
    "   \n",
    "**\\S** : cualquier car√°cter a excepci√≥n del espacio en blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1691146918317,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "oIivLgY2F4P0",
    "outputId": "68d79618-4259-42b1-caf8-03a8e8b6e457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.sa', 'osa']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \".sa\"\n",
    "re.findall(patron, cadena)\n",
    "# busca la cadena (cualquier elemento incluso el espacio) seguido de la \"sa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1691147031927,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "Yq899nheNmkG",
    "outputId": "e092b0a0-9734-4dcc-dd93-be8cbd0b38fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Fabi√°n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"\\sFabi√°n\"\n",
    "re.findall(patron, cadena)\n",
    "# busca (espacio) m√°s \"Fabi√°n\" : observe que hay solo una coindicencia que corresponde a la palabra interna que tiene un espacio antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1691147072916,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "lQ_NJ4JIN83w",
    "outputId": "66d42608-fc15-4158-daeb-27bc9c905724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rreo']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"\\Sreo\"\n",
    "re.findall(patron, cadena)\n",
    "# busca (espacio) m√°s \"Fabi√°n\" : observe que hay solo una coindicencia que corresponde a la palabra interna que tiene un espacio antes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBen50t7ONJ0"
   },
   "source": [
    "\"*\" : indica la repetici√≥n de un car√°cter cero o m√°s veces\n",
    "\n",
    "\"+\" : indica la repetici√≥n de un car√°cter una o m√°s veces\n",
    "\n",
    "?   : Es el car√°cter o cuantificador *reacio*. A√±adido a cualquiera de los anteriores se contar√° con la ocurrencia m√°s corta posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1691147313106,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "ylaAfs1COQYg",
    "outputId": "229d5c4a-52b7-4b26-9039-65fa8d0ba4b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fabi√°n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"Fabi√°n*\"\n",
    "re.findall(patron, cadena)\n",
    "# Buscar Fabia o Fabian o Fabiann ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1691147856045,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "t939a_NtPPj4",
    "outputId": "11c5d146-2e45-4189-ab3a-625ad94a2c7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fabi√°']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"Fabi√°n+\"\n",
    "re.findall(patron, cadena)\n",
    "# Buscar Fabian o Fabiann o Fabiannnn..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgFJHDMXQdAa"
   },
   "source": [
    "Veamos los siguientes ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1691147701043,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "LMLBAwWXQfTF",
    "outputId": "f39675a0-ce3b-4873-df55-8bf82e28d0ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['√°n', '√°n', 'an', 'an', 'en']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"\\Sn\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca as√≠: (cualquier caracter (sin espacio) muchas veces).. h.. (cualquiera)..h..h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1691147741581,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "XJLDYQUtPzuf",
    "outputId": "3de204dc-b746-4def-f5fc-11482f38fe5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fabi√°n', 'S√°n', 'fabian.san', 'en']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"\\S*n\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca as√≠: (cualquier caracter (sin espacio) muchas veces).. h.. (cualquiera)..h..h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1691147624674,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "nOYmYV1WQNE1",
    "outputId": "200e412e-4f3f-4e48-b49e-fe4922b02bbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fabi√°n', 'S√°n', 'fabian', '.san', 'en']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"\\S*?n\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca as√≠: (cualquier caracter (sin espacio) muchas veces).. h.. (cualquiera)..h..h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7QpE-nlR5SR"
   },
   "source": [
    "¬øC√≥mo hacemos para extraer el correo de la oraci√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE6Vbg8RR-6p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okrc4PsZRVez"
   },
   "source": [
    "**[ ]** : cualquiera de los caracteres especificados\n",
    "\n",
    "**[ ^ ]**  : al inicio de [] es la negaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1691148682386,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "8MxvuwqvUEsS",
    "outputId": "8d6ab44d-c509-48b2-fc86-22a4572d733a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'a', 'a', 'a', 'a', 'a']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"[Fa]\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca las \"F\" y las \"a\", es decir, busca lo que esta adentro individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTlvsvVIURxJ"
   },
   "outputs": [],
   "source": [
    "patron = \"[^Fa]\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca los otros caracteres que no son F o a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1691148771587,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "EGDLDvNHUV_2",
    "outputId": "c591e2ff-d330-45fe-824c-182c08a13565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fabian']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"[Ff]abian\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca Fabian y fabian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMcsPMrrUxHV"
   },
   "source": [
    "***Expresiones importantes***\n",
    "\n",
    "- \"[A-Z0-9]\"\n",
    "- \"[^A-Za-z0-9√≥√°√©√≠√∫√±]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1691148958464,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "c6UKUREsUwsy",
    "outputId": "c8e110eb-3f54-41b2-d9b6-e106ab3d2f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'F', 'S', 'P', 'L', 'N']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"[A-Z]\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca Fabian y fabian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1691148985983,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "o3ZHHKujVX7w",
    "outputId": "68773941-f5ec-44c6-d2c4-682b263cedee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'F', 'S', 'PLN']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"[A-Z]+\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca Fabian y fabian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1691149084168,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "2zNw-VQmVI4a",
    "outputId": "a1bc5d4f-f155-4a9c-9b57-2ebac847b1e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El',\n",
       " 'correo',\n",
       " 'de',\n",
       " 'Fabi',\n",
       " 'n',\n",
       " 'S',\n",
       " 'nchez',\n",
       " 'con',\n",
       " 'c',\n",
       " 'digo',\n",
       " 'AP',\n",
       " 'es',\n",
       " 'fabian',\n",
       " 'sanchez',\n",
       " 'urosario',\n",
       " 'edu',\n",
       " 'co',\n",
       " 'y',\n",
       " 'en',\n",
       " 'twitter',\n",
       " 'PLN']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patron = \"[A-Za-z]+\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca Fabian y fabian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syjEeBXFVz6z"
   },
   "outputs": [],
   "source": [
    "patron = \"[A-Za-z0-9√≥√°√©√≠√∫]+\"\n",
    "re.findall(patron, cadena)\n",
    "# Busca Fabian y fabian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CGYIolxWJQ7"
   },
   "source": [
    "Ahora bien, usaremos la instrucci√≥n *sub* para sustituir car√°cteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1691149229205,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "7nokOwKRWOq8",
    "outputId": "7f1a3b7a-89a4-4e21-d087-500e7897c00f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'El correo de Fabi√°n S√°nchez con c√≥digo AP89504 es fabian sanchez urosario edu co y en twitter PLN '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadena2 = re.sub (\"[^A-Za-z0-9√≥√°√©√≠√∫√±]+\",\" \",cadena)\n",
    "cadena2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFRQtcqSWae8"
   },
   "source": [
    "¬øQu√© efecto tiene la expresi√≥n anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhcroExWWoZf"
   },
   "source": [
    "<FONT SIZE=5 COLOR=\"purple\"> 4. TOKENIZACI√ìN </FONT>\n",
    "\n",
    "- Es el proceso de dividir las cadenas de texto de un documento en piezas m√°s peque√±as que se denominan *tokens*.\n",
    "\n",
    "- La librer√≠a NTKL tiene funciones para hacer la tokenizaci√≥n de textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4I0_fZlXR2k"
   },
   "source": [
    "Importaremos la librer√≠a al espacio de trabajo y la funci√≥n *word_tokenize*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1691155865749,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "HNrQrvGsXHbT"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# separa cuando encuentra espacio y car√°cteres especiales\n",
    "from nltk import word_tokenize\n",
    "# separa cuando encuentra espacio y punto\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpe6Kv-VX0oy"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9c7SZ_xYcRr"
   },
   "source": [
    "Veamos dos ejemplos con las cadenas de texto que hemos abordado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyGj3mfXXhD7"
   },
   "outputs": [],
   "source": [
    "words_cadena = nltk.word_tokenize(cadena)\n",
    "words_cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N5QPgP4Yq5V"
   },
   "outputs": [],
   "source": [
    "nltk.wordpunct_tokenize(cadena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heMntbJDYPcC"
   },
   "outputs": [],
   "source": [
    "words_texto = nltk.word_tokenize(texto)\n",
    "words_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tgbGT2kntHf"
   },
   "source": [
    "<FONT SIZE=5 COLOR=\"purple\"> 5. STOP WORDS </FONT>\n",
    "\n",
    "- Son palabras que no aportan al significado de la oraciones : preprosiciones, conjunciones, adverbios, art√≠culos, etc.\n",
    "\n",
    "- NLTK tiene para una serie de idiomas un listado de Stop Words.\n",
    "\n",
    "- Podemos crear nuestra propia bolsa de palabras dependiendo del lenguaje y contexto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1691155884973,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "sigSL-4ova3P"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGnP-zh4wHgQ"
   },
   "source": [
    "Bolsa de palabras de ingl√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1691155907187,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "dVKY1flevwh2",
    "outputId": "131693eb-91aa-482c-e478-a7793cb20b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you', 'm', 'she', 'itself', 'her', 'their', 'yourself', 'does', 'but', 'out', 'all', 'mustn', 'been', 'further', 'down', 'few', 'mightn', 'my', 'once', 'is', 'or', 'y', 'very', 'have', 'his', 'between', 'so', 'them', 'don', 'how', 'after', 'll', \"she's\", 'to', \"isn't\", 'whom', 'through', 'd', 'should', 'on', 'then', 'of', 'what', 'not', 'we', 'herself', 'such', 'that', 'why', 'and', 'this', 'if', \"you're\", \"hasn't\", 'just', 'some', 'into', 'under', 'ain', 'aren', 'hadn', 'hers', 'as', \"weren't\", 'same', 'me', 'theirs', 'wouldn', 'nor', 'any', 'from', 'isn', 'did', 'your', \"you'll\", 'each', 'ourselves', 'over', 'our', 'didn', \"shan't\", 'during', \"shouldn't\", 'him', 'won', 's', \"you've\", 'a', \"aren't\", \"mustn't\", 'below', 't', 'has', 'until', 'now', 'doesn', 'haven', 'shouldn', 'i', 'ours', 'hasn', 'an', 'when', 'because', 'myself', \"that'll\", 'than', \"wouldn't\", 'themselves', 'himself', 'with', 'will', 'doing', 'can', 'above', 'was', 'up', 'do', 'too', \"haven't\", 'more', 'yourselves', 'were', 'before', \"won't\", 'are', 'again', 'wasn', 'am', 've', \"couldn't\", 'against', 'only', 'it', 'there', 'both', 'they', \"doesn't\", 'being', 'at', \"mightn't\", 'about', 'yours', 'couldn', 'own', \"should've\", 'where', 'most', \"didn't\", 'weren', \"hadn't\", 'o', 'shan', \"it's\", 'by', 'having', 'the', \"needn't\", \"don't\", 'while', 'be', \"you'd\", 'its', 'for', 'ma', 'off', 'no', 'who', 'he', 'other', 're', 'needn', 'those', 'in', 'had', 'here', 'these', 'which', \"wasn't\"}\n"
     ]
    }
   ],
   "source": [
    "print(set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NW3TOmUwKFO"
   },
   "source": [
    "Bolsa de palabras en espa√±ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1691156016951,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "f59u5wgGwMoe",
    "outputId": "e034c691-0647-440d-b641-875067f47d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'con', 'hubiese', 'algo', 'suya', 'tengamos', 'donde', 'nosotros', 'unos', 'tendr√≠an', 'sentidas', 'm√≠os', 'habido', 'tenga', 'suyos', 'tuve', 'tuviera', 'estuviese', 'tendr√°n', 'estuviste', 'sobre', 'esto', 'tuvierais', 'estar√°s', 'habr√©is', 'hubieras', 'se√°is', 'hay√°is', 'eso', 'tuvieron', 'porque', 'tendr√©', 'a', 'ni', 'estaremos', 'estar√©', 'habr√©', 'hayan', 'mucho', 'nos', 'm√≠a', 'nuestros', 'nuestro', 'hab√©is', 'esa', 'entre', 'hubimos', 'tiene', 'nuestras', 'ten√≠amos', 'hube', 'sintiendo', 'habidas', 'poco', 'su', 'estar√©is', 'tuya', 'fueran', 'sentidos', 'habr√≠ais', 'fu√©ramos', 'estuvieran', 'hasta', 'est√°s', 'ese', 'tienes', 'estar√≠as', 'ten√©is', 'estuve', 'durante', 'estaban', 'desde', 'tuvo', 'habr√°', 'seamos', 'estuvieron', 'estos', 'fueses', 'fueseis', 'tendremos', 'hubieron', 'estar√≠ais', 'eras', 'tuvieras', 'fuimos', 'tuvimos', 'muchos', 'est√°', 'hubi√©semos', 'teniendo', 'esas', 'vuestra', 'tus', 'tuvieran', 'hab√≠as', 'ante', 'habr√≠as', 'soy', 'sentido', 'otro', 'tendr√≠a', 's√≠', 'estas', 'fu√©semos', 'tuvieseis', 'tuvi√©semos', 'de', 'otros', 'vuestras', 'estados', 'quien', 'otras', 'fuesen', 'est√°is', 'del', 'fui', 'tienen', 'me', 'otra', 'fueras', 'estuvo', 'nada', 'se', 'tendr√≠amos', 'hab√≠a', 'has', 'hab√≠ais', 'te', 'hubiera', 'cuando', 'tendr√°s', 'haya', 'era', 'le', 'que', 'sin', 'fuisteis', 'estad', 'habr√≠an', 'sois', 'tenida', 'estuvimos', 'cual', 'contra', 'yo', 'una', 'hubi√©ramos', 'sea', 'vuestro', 'tenidas', 'est√°bamos', 'fuese', 'son', 'sentida', 'estemos', 'ser√≠a', 'habremos', 'estuvi√©ramos', 'fue', 'para', 'fuerais', 'ten√≠as', 'siente', 'he', 'tuvi√©ramos', 'hubieran', 'estar', 'teng√°is', 'un', 'la', 'al', 'estada', 'sentid', 'han', 'lo', 'y', 'os', 'ser√≠as', 'estuviesen', 't√∫', 'e', 'tuviste', 'hab√≠an', 'es', 'quienes', 'hayamos', 'ser√≠an', 'en', 'todos', 'estuviera', 'nuestra', 'estar√°', 'ser√°', 'ser√≠ais', 'estuvieras', 'estuvi√©semos', 'hubiste', 'ser√°s', 'estuvisteis', 'tambi√©n', 'estoy', 'ha', 'el', 'nosotras', 'estar√°n', 'suyas', 'estabais', 'tenidos', 'tenido', 'por', 'hubo', 'est√©s', 'esos', 'estado', 'estar√≠a', 'tengan', 'qu√©', 'fuera', 'tendr√©is', 'est√°n', 'las', 'todo', 'sus', '√©ramos', 'tuviesen', 'ellas', 'hubieseis', 'o', 'ya', 'hubierais', 'vuestros', 'les', 'hab√≠amos', 'tendr√°', 'estar√≠amos', 'esta', 'hubieses', 'estuvieseis', 'tuyas', 'tuvieses', 'antes', 'habr√°s', 'tenemos', 'habr√≠amos', 'tanto', 'est√©is', 'fueron', 'm√°s', 'mi', 'tened', 'suyo', 'tuvisteis', 'tu', 'estuvierais', 'estamos', 'sean', 'como', 'm√≠as', 'ser√≠amos', 'habr√°n', 'tuviese', 'erais', 'eran', 'estaba', 'ten√≠a', 'muy', 'vosotros', 'algunos', 'hemos', 'tengo', 'tendr√≠as', 'estuvieses', 'algunas', 'habr√≠a', 'vosotras', 'm√≠o', 'estando', 'hayas', 'uno', 'estar√≠an', 'seas', 'ti', 'estabas', 'ellos', 'est√©', 'habida', 'tuyo', 'los', 'habiendo', 'ser√°n', 'ser√©is', 'mis', 'ella', 'm√≠', 'somos', 'hay', '√©l', 'eres', 'estadas', 'habidos', 'seremos', 'tuyos', 'tendr√≠ais', 'tengas', 'hubisteis', 'est√©n', 'pero', 'no', 'ten√≠ais', 'este', 'hubiesen', 'ser√©', 'fuiste', 'ten√≠an'}\n"
     ]
    }
   ],
   "source": [
    "print(set(stopwords.words(\"spanish\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbPbpb76wWIW"
   },
   "source": [
    "Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1691156378828,
     "user": {
      "displayName": "FABIAN SANCHEZ SALAZAR",
      "userId": "13785856712232060994"
     },
     "user_tz": 300
    },
    "id": "3VRt5bvLwXaI",
    "outputId": "74b710e4-b30f-4922-f8ba-c88903ca5c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "por\n",
      "en\n",
      "la\n"
     ]
    }
   ],
   "source": [
    "doc = \"Un radar multa a Fabian Sanchez por conducir demasiado rapido en la autopista\"\n",
    "words = nltk.word_tokenize(doc)\n",
    "for word in words:\n",
    "        if word in stopwords.words('spanish'):\n",
    "            print (word)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOb2FMzyfadT17FImh/9GKl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
